{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the libraries and read the data files\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "import os, sys, email\n",
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import timeit\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql,re\n",
    "\n",
    "host = \"127.0.0.1\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "password = \"\"\n",
    "database = \"digital_talent\"\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host=host,\n",
    "    port=int(port),\n",
    "    user=user,\n",
    "    passwd=password,\n",
    "    db=database,\n",
    "    charset='utf8mb4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waktu</th>\n",
       "      <th>url</th>\n",
       "      <th>tone</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>http://en.qantara.de/content/indonesias-joko-w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>indonesia's joko widodo names muslim cleric as...</td>\n",
       "      <td>indonesia's joko widodo names muslim cleric as...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>http://en.republika.co.id/berita/en/national-p...</td>\n",
       "      <td>2.721088</td>\n",
       "      <td>it hurts to see elections split the community:...</td>\n",
       "      <td>jokowi says indonesia is respected abroad for ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>http://jakartaglobe.id/human-rights-news/democ...</td>\n",
       "      <td>-5.913979</td>\n",
       "      <td>democratic maturity will ensure peaceful elect...</td>\n",
       "      <td>the president also highlighted the role of sta...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>http://jakartaglobe.id/news/democratic-maturit...</td>\n",
       "      <td>-5.913979</td>\n",
       "      <td>democratic maturity will ensure peaceful elect...</td>\n",
       "      <td>the president also highlighted the role of sta...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>http://jakartaglobe.id/news/islamic-scholar-ma...</td>\n",
       "      <td>2.647059</td>\n",
       "      <td>islamic scholar ma'ruf amin becomes jokowi's r...</td>\n",
       "      <td>president joko 'jokowi' widodo has chosen ma'r...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        waktu                                                url      tone  \\\n",
       "0  2018-08-10  http://en.qantara.de/content/indonesias-joko-w...  0.000000   \n",
       "1  2018-06-06  http://en.republika.co.id/berita/en/national-p...  2.721088   \n",
       "2  2018-08-18  http://jakartaglobe.id/human-rights-news/democ... -5.913979   \n",
       "3  2018-08-16  http://jakartaglobe.id/news/democratic-maturit... -5.913979   \n",
       "4  2018-08-09  http://jakartaglobe.id/news/islamic-scholar-ma...  2.647059   \n",
       "\n",
       "                                               title  \\\n",
       "0  indonesia's joko widodo names muslim cleric as...   \n",
       "1  it hurts to see elections split the community:...   \n",
       "2  democratic maturity will ensure peaceful elect...   \n",
       "3  democratic maturity will ensure peaceful elect...   \n",
       "4  islamic scholar ma'ruf amin becomes jokowi's r...   \n",
       "\n",
       "                                             content Sentiment  \n",
       "0  indonesia's joko widodo names muslim cleric as...   Neutral  \n",
       "1  jokowi says indonesia is respected abroad for ...  Positive  \n",
       "2  the president also highlighted the role of sta...  Negative  \n",
       "3  the president also highlighted the role of sta...  Negative  \n",
       "4  president joko 'jokowi' widodo has chosen ma'r...  Positive  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read(sql):\n",
    "    df = pd.read_sql_query(sql,conn)\n",
    "    return df\n",
    "\n",
    "news = read(\"SELECT * FROM event_election_new WHERE title != 'not found'\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    import string\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    return s\n",
    "\n",
    "news['content'] = news['content'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves',\n",
       "       u'you', u\"you're\", u\"you've\", u\"you'll\", u\"you'd\", u'your',\n",
       "       u'yours', u'yourself', u'yourselves', u'he', u'him', u'his',\n",
       "       u'himself', u'she', u\"she's\", u'her', u'hers', u'herself', u'it',\n",
       "       u\"it's\", u'its', u'itself', u'they', u'them', u'their', u'theirs',\n",
       "       u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that',\n",
       "       u\"that'll\", u'these', u'those', u'am', u'is', u'are', u'was',\n",
       "       u'were', u'be', u'been', u'being', u'have', u'has', u'had',\n",
       "       u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the',\n",
       "       u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while',\n",
       "       u'of', u'at', u'by', u'for', u'with', u'about', u'against',\n",
       "       u'between', u'into', u'through', u'during', u'before', u'after',\n",
       "       u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out',\n",
       "       u'on', u'off', u'over', u'under', u'again', u'further', u'then',\n",
       "       u'once', u'here', u'there', u'when', u'where', u'why', u'how',\n",
       "       u'all', u'any', u'both', u'each', u'few', u'more', u'most',\n",
       "       u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own',\n",
       "       u'same', u'so', u'than', u'too', u'very', u's', u't', u'can',\n",
       "       u'will', u'just', u'don', u\"don't\", u'should', u\"should've\", u'now',\n",
       "       u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren',\n",
       "       u\"aren't\", u'couldn', u\"couldn't\", u'didn', u\"didn't\", u'doesn',\n",
       "       u\"doesn't\", u'hadn', u\"hadn't\", u'hasn', u\"hasn't\", u'haven',\n",
       "       u\"haven't\", u'isn', u\"isn't\", u'ma', u'mightn', u\"mightn't\",\n",
       "       u'mustn', u\"mustn't\", u'needn', u\"needn't\", u'shan', u\"shan't\",\n",
       "       u'shouldn', u\"shouldn't\", u'wasn', u\"wasn't\", u'weren', u\"weren't\",\n",
       "       u'won', u\"won't\", u'wouldn', u\"wouldn't\"], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the stopwords from nltk library\n",
    "sw = stopwords.words('english')\n",
    "# displaying the stopwords\n",
    "np.array(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(text):\n",
    "    '''a function for removing the stopword'''\n",
    "    # removing the stop words and lowercasing the selected words\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    # joining the list of words with space separator\n",
    "    return \" \".join(text)\n",
    "\n",
    "news['content'] = news['content'].apply(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabeledSentence1 = gensim.models.doc2vec.TaggedDocument\n",
    "\n",
    "all_content = []\n",
    "texts = []\n",
    "\n",
    "j=0\n",
    "k=0\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "p_stemmer = PorterStemmer()\n",
    "for em in emails_df.Subjcontent:           \n",
    "    #Data cleaning\n",
    "    clean_content = email_cleaning(em)\n",
    "    \n",
    "    #Pre-processing\n",
    "    processed_email = preprocessing(clean_content)\n",
    "    \n",
    "    # add tokens to list\n",
    "    if processed_email:\n",
    "        all_content.append(LabeledSentence1(processed_email,[j]))\n",
    "        j+=1\n",
    "        \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegexpTokenizer(pattern='\\\\w+', gaps=False, discard_empty=True, flags=56)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
